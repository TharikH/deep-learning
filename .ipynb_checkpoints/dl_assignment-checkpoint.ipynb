{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/TharikH/deep-learning/blob/main/dl_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxC5XjBomovq",
    "outputId": "50f0bffd-fa97-432c-9fe0-0ca91acf5c5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 21:39:50.212676: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-19 21:39:50.842116: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tharikh/plugin/ns-allinone-2.35/otcl-1.14:/home/tharikh/plugin/ns-allinone-2.35/lib\n",
      "2023-03-19 21:39:50.842190: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-19 21:39:52.121399: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tharikh/plugin/ns-allinone-2.35/otcl-1.14:/home/tharikh/plugin/ns-allinone-2.35/lib\n",
      "2023-03-19 21:39:52.121549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tharikh/plugin/ns-allinone-2.35/otcl-1.14:/home/tharikh/plugin/ns-allinone-2.35/lib\n",
      "2023-03-19 21:39:52.121570: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# in colab uncomment below statement\n",
    "# !pip install wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "import copy\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uib1izEEoToJ",
    "outputId": "c11588ed-ee88-456b-a446-9a3b8d56ece4"
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fEFcyAeBo_D6"
   },
   "outputs": [],
   "source": [
    "num_train_samples = X_train.shape[0]\n",
    "num_size = X_train.shape[1] * X_train.shape[2]\n",
    "num_test_samples = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tRTo19OU1L3p",
    "outputId": "f098b3cd-da4e-4c3d-ce8d-0c392ea85eef"
   },
   "outputs": [],
   "source": [
    "input_size=num_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdNI9lnQ2oIM"
   },
   "source": [
    "## plot 1 sample image for each class - run below to log image also into wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "AZtSRC16y5b5",
    "outputId": "cccbce4f-2590-4ace-e426-8e164330bcde"
   },
   "outputs": [],
   "source": [
    "example_y = []\n",
    "example_x = []\n",
    "plt.figure(figsize=(10,10))\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    \n",
    "k=0\n",
    "wandb.login(key = 'c425b887e2c725018a7f3a772582610fa54ef52c')\n",
    "\n",
    "for i in range(num_train_samples):\n",
    "  if Y_train[i] not in example_y:\n",
    "    example_y.append(Y_train[i])\n",
    "    example_x.append(X_train[i])\n",
    "    \n",
    "    wandb.init(project=\"dl-project-final-production\")\n",
    "    wandb.run.name = f'{class_names[Y_train[i]]}'\n",
    "    wandb.log({\"examples\": [wandb.Image(X_train[i],caption=class_names[Y_train[i]])]})\n",
    "    \n",
    "    plt.subplot(5,5,k+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[Y_train[i]])\n",
    "    k+=1\n",
    "    if k == 10:\n",
    "      break\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaupL4eL2QoO"
   },
   "source": [
    "## Question 3,4 and 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TfjhpkZr-T5I"
   },
   "outputs": [],
   "source": [
    "#class having all required activations\n",
    "\n",
    "class Activations():\n",
    "  '''\n",
    "  It contains all activations required with its derivatives.\n",
    "  call object.activate(name) function to get the corresponding function, then pass vectors/matrix/values on to these fucntions\n",
    "  similarly call object.derivative(name) to get derivative function.\n",
    "  The names are :\n",
    "  -> sigmoid\n",
    "  -> softmax\n",
    "  -> tanh\n",
    "  -> relu\n",
    "  -> identity\n",
    "  \n",
    "  '''\n",
    "  def __init__(self):\n",
    "    self.activation_dict={\n",
    "        \"sigmoid\":self.sigmoid,\n",
    "        \"softmax\":self.softmax,\n",
    "        \"tanh\":self.tanh,\n",
    "        \"relu\":self.relu,\n",
    "        \"identity\":self.identity\n",
    "    }\n",
    "    self.derivative_dict={\n",
    "        \"sigmoid\":self.sigmoidDerivative,\n",
    "        \"softmax\":self.softmaxDerivative,\n",
    "        \"tanh\":self.tanhDerivative,\n",
    "        \"relu\":self.reluDerivative,\n",
    "        \"identity\":self.identity\n",
    "    }\n",
    "\n",
    "  def activate(self, activation_function = \"sigmoid\"):\n",
    "    return self.activation_dict[activation_function]\n",
    "\n",
    "  def derivate(self,activation_function = \"sigmoid\"):\n",
    "    return self.derivative_dict[activation_function]\n",
    "\n",
    "  def sigmoid(self, x):\n",
    "    z = x.copy()\n",
    "    z[x < 0] = np.exp(x[x < 0])/(1 + np.exp(x[x<0]))\n",
    "    z[x >= 0] = 1/(1+np.exp(-x[x >= 0]))\n",
    "    return z\n",
    "\n",
    "  def softmax(self, x):\n",
    "    max_element = np.max(x,axis=0)\n",
    "    z = np.exp(x - max_element)\n",
    "    total = sum(z)\n",
    "    z = z/total\n",
    "    return z\n",
    "  \n",
    "  def tanh(self, x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "  def identity(self,x):\n",
    "    return x\n",
    "\n",
    "  def identityDerivative(self, x):\n",
    "    return np.ones(x.shape)\n",
    "\n",
    "  def tanhDerivative(self, x):\n",
    "    z = self.tanh(x)\n",
    "    return 1 - z**2\n",
    "\n",
    "  def softmaxDerivative(self,x):\n",
    "    pass\n",
    "  \n",
    "  def sigmoidDerivative(self,x):\n",
    "    z = self.sigmoid(x)\n",
    "    return  z*(1 - z)\n",
    "  \n",
    "  def relu(self,x):\n",
    "    return np.maximum(x,0)\n",
    "  \n",
    "  def reluDerivative(self,x):\n",
    "    z = x.copy()\n",
    "    z[x < 0]=0\n",
    "    z[x > 0]=1\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "znaRtyTqZ-dT"
   },
   "outputs": [],
   "source": [
    "# class having all losses and its derivatives\n",
    "class Loss():\n",
    "  '''\n",
    "  It contains all Loss and its corresponding derivative with last layer (a_L), assuming last layer activation is softmax.\n",
    "  Initialize the object with name of loss.\n",
    "  call object.findLoss() function to get the corresponding function, then pass appropriate parameter\n",
    "  like Y, Y_hat etc.\n",
    "    \n",
    "  The initializations are :\n",
    "    -> cross_entropy\n",
    "    -> mean_squared_error\n",
    "  \n",
    "  '''\n",
    "    \n",
    "    \n",
    "  def __init__(self,loss_name):\n",
    "    self.loss_dict = {\n",
    "        'cross_entropy':self.crossEntropy,\n",
    "        'mean_squared_error':self.mse\n",
    "    }\n",
    "    self.loss_derivative_dict = {\n",
    "        'cross_entropy':self.crossEntropyDerivativeWithL,\n",
    "        'mean_squared_error':self.mseDerivativeWithL\n",
    "    }\n",
    "    self.loss_name = loss_name\n",
    "\n",
    "  def findLoss(self):\n",
    "    return self.loss_dict[self.loss_name]\n",
    "  \n",
    "  def findDerivative(self):\n",
    "    return self.loss_derivative_dict[self.loss_name]\n",
    "\n",
    "  def findOneHotVector(self,Y_hat, Y):\n",
    "    vector = np.zeros(Y_hat.shape)\n",
    "    for i in range(Y_hat.shape[1]):\n",
    "      vector[:,i][Y[i]] = 1\n",
    "    \n",
    "    return vector\n",
    "    \n",
    "  def crossEntropy(self ,Y_hat, Y, weight_decay=0,W=[]):\n",
    "    loss=0\n",
    "    num_samples = Y_hat.shape[1]\n",
    "    for i in range(num_samples):\n",
    "      loss+=np.log(Y_hat[:,i][Y[i]]  if Y_hat[:,i][Y[i]] != 0 else 1e-9)\n",
    "    \n",
    "    decay_loss = 0\n",
    "    for i in range(len(W)):\n",
    "        decay_loss+=np.sum(W[i] ** 2)\n",
    "\n",
    "\n",
    "    return (-loss + (weight_decay * decay_loss)/2)/num_samples\n",
    "\n",
    "  def crossEntropyDerivativeWithL(self,Y_hat, Y):\n",
    "    return -(self.findOneHotVector(Y_hat,Y) - Y_hat)\n",
    "\n",
    "  def mse(self, Y_hat, Y,weight_decay=0,W=[]):\n",
    "    m,n = Y_hat.shape\n",
    "    one_hot_Y = self.findOneHotVector(Y_hat,Y)\n",
    "    diff_matrix = (Y_hat - one_hot_Y)**2\n",
    "    loss = np.sum(diff_matrix)\n",
    "    \n",
    "    decay_loss = 0\n",
    "    for i in range(len(W)):\n",
    "        decay_loss+=np.sum(W[i] ** 2)\n",
    "        \n",
    "    \n",
    "    return (loss/(m*n)) + ((weight_decay * decay_loss)/2)/n\n",
    "\n",
    "  def mseDerivativeWithL(self, Y_hat , Y,weight_decay=0,W=[]):\n",
    "    derivative = np.zeros(Y_hat.shape)\n",
    "    num_rows,num_samples = Y_hat.shape\n",
    "    one_hot_Y = self.findOneHotVector(Y_hat,Y)\n",
    "    for m in range(num_samples):\n",
    "        for j in range(num_rows):\n",
    "            s=0\n",
    "            for i in range(num_rows):\n",
    "                if j == i:\n",
    "                    s+=(Y_hat[i,m] - one_hot_Y[i,m])*Y_hat[i,m]*(1 - Y_hat[j,m])\n",
    "                else:\n",
    "                    s+=(Y_hat[i,m] - one_hot_Y[i,m])*Y_hat[i,m]*(-Y_hat[j,m])\n",
    "                \n",
    "            derivative[j,m] = 2*s\n",
    "    return derivative\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tVu-t4PF6tiJ"
   },
   "outputs": [],
   "source": [
    "# class having all the weight initializations\n",
    "class WeightInit():\n",
    "  '''\n",
    "  It contains all weight initializations. initialize the object with name of initialization\n",
    "  call object.initializeWeight() function to get the corresponding function, then pass shapes to get corresponding initializations\n",
    "    \n",
    "  The initializations are :\n",
    "    -> zero\n",
    "    -> random\n",
    "    -> xavier\n",
    "  \n",
    "  '''\n",
    "    \n",
    "  def __init__(self,weight_name):\n",
    "    self.weight_name = weight_name\n",
    "    self.weight_dict={\n",
    "        \"zero\":self.zeroInit,\n",
    "        \"random\":self.randomInit,\n",
    "        \"xavier\":self.xavierInit\n",
    "    }\n",
    "\n",
    "  def initializeWeight(self):\n",
    "    return self.weight_dict[self.weight_name]\n",
    "    \n",
    "  \n",
    "  def zeroInit(self, shape, flag=0):\n",
    "    x = np.zeros(shape)\n",
    "    return x\n",
    "\n",
    "  def randomInit(self, shape, flag=0):\n",
    "    x = np.random.normal(loc=0,scale=1,size=shape)\n",
    "    return x\n",
    "\n",
    "  \n",
    "  def xavierInit(self, shape, flag=0):\n",
    "    x = np.random.randn(*shape) * np.sqrt(2/shape[0]) if flag == 0 else self.zeroInit(shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "V2gS7xaQ50Hd"
   },
   "outputs": [],
   "source": [
    "# classes having all the optimizers\n",
    "class Optimizer():\n",
    "    \n",
    "  '''\n",
    "  It contains all optimizers. initialize the object with name of optimizer\n",
    "  call object.optimize() function to get the corresponding function, then pass appropriate parameter\n",
    "  like training data, validation data, learning rate etc.\n",
    "    \n",
    "  The initializations are :\n",
    "    -> gradient descent\n",
    "    -> stochastic gradient descent\n",
    "    -> momentum\n",
    "    -> nesterov\n",
    "    -> rmsprop\n",
    "    -> adam\n",
    "    -> nadam\n",
    "  \n",
    "  '''\n",
    "\n",
    "  def __init__(self,optimizer_name=\"gd\"):\n",
    "    self.optimizer_name = optimizer_name\n",
    "    self.optimizer_dict={\n",
    "        \"gd\":self.gradient_descent,\n",
    "        \"sgd\":self.gradient_descent,\n",
    "        \"momentum\":self.momentum,\n",
    "        \"nag\":self.nesterov,\n",
    "        \"rmsprop\":self.rmsprop,\n",
    "        \"adam\" : self.adam,\n",
    "        \"nadam\" : self.nadam\n",
    "    }\n",
    "\n",
    "  def optimize(self):\n",
    "    return self.optimizer_dict[self.optimizer_name]\n",
    "    \n",
    "  \n",
    "  def gradient_descent(self, nn, X, Y, X_val, Y_val, lr, epochs, batch_size,indexes_for_batch,parameters = [], weight_decay = 0):\n",
    "\n",
    "    num_data = X.shape[1]\n",
    "\n",
    "    val_loss_list = []\n",
    "    train_loss_list = []\n",
    "    val_accuracy_list = []\n",
    "    train_accuracy_list = []\n",
    "    \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      for batch in range(0,num_data,batch_size):\n",
    "        X_batch = X[:,indexes_for_batch[batch:batch + batch_size]]\n",
    "        Y_batch = Y[indexes_for_batch[batch:batch + batch_size]]\n",
    "\n",
    "        # self.W,self.b = self.initializeWeights()\n",
    "        a_values,h_values = nn.forwardpropogation(X_batch)\n",
    "        delta_W, delta_b = nn.backpropogation(X_batch,Y_batch,a_values, h_values)\n",
    "        # print(np.sum(delta_W[0], axis = 0))\n",
    "        for j in range(nn.num_hidden_layer + 1):\n",
    "          nn.W[j] = nn.W[j] - lr * delta_W[nn.num_hidden_layer - j] - lr*weight_decay*nn.W[j]\n",
    "          nn.b[j] = nn.b[j] - lr * delta_b[nn.num_hidden_layer - j]\n",
    "\n",
    "      Y_hat = nn.feedforward(X)\n",
    "      loss_value = nn.loss(Y_hat,Y,weight_decay,nn.W)\n",
    "      print(f\"epoch: {epoch} => loss = {loss_value}\")\n",
    "      y_val_predict = nn.feedforward(X_val)\n",
    "      y_train_predict = nn.feedforward(X)\n",
    "\n",
    "      validation_loss = nn.loss(y_val_predict,Y_val,weight_decay,nn.W)\n",
    "      training_loss = nn.loss(y_train_predict,Y,weight_decay,nn.W)\n",
    "\n",
    "      validation_accuracy = nn.calculateAccuracy(X_val, Y_val)\n",
    "      training_accuracy = nn.calculateAccuracy(X, Y)\n",
    "\n",
    "      \n",
    "      val_loss_list.append(validation_loss)\n",
    "      val_accuracy_list.append(validation_accuracy)\n",
    "      train_loss_list.append(training_loss)\n",
    "      train_accuracy_list.append(training_accuracy)\n",
    "    \n",
    "    return val_loss_list,val_accuracy_list,train_loss_list,train_accuracy_list\n",
    "    \n",
    "  def momentum(self, nn, X, Y, X_val, Y_val, lr, epochs, batch_size,indexes_for_batch,parameters = [0.9], weight_decay = 0):\n",
    "    num_data = X.shape[1]\n",
    "    ut_w,ut_b = nn.initializeWeights(\"zero\")\n",
    "    beta = parameters[0]\n",
    "\n",
    "    val_loss_list = []\n",
    "    train_loss_list = []\n",
    "    val_accuracy_list = []\n",
    "    train_accuracy_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      for batch in range(0,num_data,batch_size):\n",
    "        X_batch = X[:,indexes_for_batch[batch:batch + batch_size]]\n",
    "        Y_batch = Y[indexes_for_batch[batch:batch + batch_size]]\n",
    "\n",
    "        # self.W,self.b = self.initializeWeights()\n",
    "        a_values,h_values = nn.forwardpropogation(X_batch)\n",
    "        delta_W, delta_b = nn.backpropogation(X_batch,Y_batch,a_values, h_values)\n",
    "        # print(np.sum(delta_W[0], axis = 0))\n",
    "        for j in range(nn.num_hidden_layer + 1):\n",
    "          ut_w[j] = beta*ut_w[j] + delta_W[nn.num_hidden_layer - j]\n",
    "          ut_b[j] = beta*ut_b[j] + delta_b[nn.num_hidden_layer - j] \n",
    "\n",
    "          nn.W[j] = nn.W[j] - lr * ut_w[j] - lr*weight_decay*nn.W[j]\n",
    "          nn.b[j] = nn.b[j] - lr * ut_b[j]\n",
    "\n",
    "      Y_hat = nn.feedforward(X)\n",
    "      loss_value = nn.loss(Y_hat,Y,weight_decay,nn.W)\n",
    "      print(f\"epoch: {epoch} => loss = {loss_value}\")\n",
    "      y_val_predict = nn.feedforward(X_val)\n",
    "      y_train_predict = nn.feedforward(X)\n",
    "\n",
    "      validation_loss = nn.loss(y_val_predict,Y_val,weight_decay,nn.W)\n",
    "      training_loss = nn.loss(y_train_predict,Y,weight_decay,nn.W)\n",
    "\n",
    "      validation_accuracy = nn.calculateAccuracy(X_val, Y_val)\n",
    "      training_accuracy = nn.calculateAccuracy(X, Y)\n",
    "\n",
    "      \n",
    "      val_loss_list.append(validation_loss)\n",
    "      val_accuracy_list.append(validation_accuracy)\n",
    "      train_loss_list.append(training_loss)\n",
    "      train_accuracy_list.append(training_accuracy)\n",
    "    \n",
    "    return val_loss_list,val_accuracy_list,train_loss_list,train_accuracy_list\n",
    "    \n",
    "  def nesterov(self, nn, X, Y, X_val, Y_val, lr, epochs, batch_size,indexes_for_batch,parameters = [0.9], weight_decay = 0):\n",
    "    num_data = X.shape[1]\n",
    "    ut_w,ut_b = nn.initializeWeights(\"zero\")\n",
    "    beta = parameters[0]\n",
    "\n",
    "    val_loss_list = []\n",
    "    train_loss_list = []\n",
    "    val_accuracy_list = []\n",
    "    train_accuracy_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      for batch in range(0,num_data,batch_size):\n",
    "        X_batch = X[:,indexes_for_batch[batch:batch + batch_size]]\n",
    "        Y_batch = Y[indexes_for_batch[batch:batch + batch_size]]\n",
    "  \n",
    "        # self.W,self.b = self.initializeWeights()\n",
    "        a_values,h_values = nn.forwardpropogation(X_batch)\n",
    "\n",
    "        old_W = copy.deepcopy(nn.W)\n",
    "        old_b = copy.deepcopy(nn.b)\n",
    "        \n",
    "        for k in range(nn.num_hidden_layer + 1):\n",
    "          nn.W[k] = nn.W[k] - beta *  ut_w[k]\n",
    "          nn.b[k] = nn.b[k] - beta *  ut_b[k]\n",
    "\n",
    "        \n",
    "        delta_W, delta_b = nn.backpropogation(X_batch,Y_batch,a_values, h_values)\n",
    "        # print(np.sum(delta_W[0], axis = 0))\n",
    "        for j in range(nn.num_hidden_layer + 1):\n",
    "          ut_w[j] = beta*ut_w[j] + delta_W[nn.num_hidden_layer - j]\n",
    "          ut_b[j] = beta*ut_b[j] + delta_b[nn.num_hidden_layer - j] \n",
    "\n",
    "          nn.W[j] = old_W[j] - lr * ut_w[j] - lr*weight_decay*nn.W[j]\n",
    "          nn.b[j] = old_b[j] - lr * ut_b[j]\n",
    "\n",
    "      Y_hat = nn.feedforward(X)\n",
    "      loss_value = nn.loss(Y_hat,Y,weight_decay,nn.W)\n",
    "      print(f\"epoch: {epoch} => loss = {loss_value}\")\n",
    "      y_val_predict = nn.feedforward(X_val)\n",
    "      y_train_predict = nn.feedforward(X)\n",
    "\n",
    "      validation_loss = nn.loss(y_val_predict,Y_val,weight_decay,nn.W)\n",
    "      training_loss = nn.loss(y_train_predict,Y,weight_decay,nn.W)\n",
    "\n",
    "      validation_accuracy = nn.calculateAccuracy(X_val, Y_val)\n",
    "      training_accuracy = nn.calculateAccuracy(X, Y)\n",
    "\n",
    "      \n",
    "      val_loss_list.append(validation_loss)\n",
    "      val_accuracy_list.append(validation_accuracy)\n",
    "      train_loss_list.append(training_loss)\n",
    "      train_accuracy_list.append(training_accuracy)\n",
    "    \n",
    "    return val_loss_list,val_accuracy_list,train_loss_list,train_accuracy_list\n",
    "    \n",
    "\n",
    "\n",
    "  def rmsprop(self, nn, X, Y,X_val, Y_val, lr, epochs, batch_size,indexes_for_batch,parameters = [0.9,0.1], weight_decay = 0):\n",
    "    num_data = X.shape[1]\n",
    "    vt_w,vt_b = nn.initializeWeights(\"zero\")\n",
    "    beta = parameters[0]\n",
    "    epsilon = parameters[1]\n",
    "\n",
    "    val_loss_list = []\n",
    "    train_loss_list = []\n",
    "    val_accuracy_list = []\n",
    "    train_accuracy_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      for batch in range(0,num_data,batch_size):\n",
    "        X_batch = X[:,indexes_for_batch[batch:batch + batch_size]]\n",
    "        Y_batch = Y[indexes_for_batch[batch:batch + batch_size]]\n",
    "\n",
    "        # self.W,self.b = self.initializeWeights()\n",
    "        a_values,h_values = nn.forwardpropogation(X_batch)\n",
    "        delta_W, delta_b = nn.backpropogation(X_batch,Y_batch,a_values, h_values)\n",
    "        # print(np.sum(delta_W[0], axis = 0))\n",
    "        for j in range(nn.num_hidden_layer + 1):\n",
    "          vt_w[j] = beta*vt_w[j] + (1 - beta) * np.multiply(delta_W[nn.num_hidden_layer - j],delta_W[nn.num_hidden_layer - j]) \n",
    "          vt_b[j] = beta*vt_b[j] + (1 - beta) * np.multiply(delta_b[nn.num_hidden_layer - j],delta_b[nn.num_hidden_layer - j])\n",
    "\n",
    "          nn.W[j] = nn.W[j] - np.divide(lr * delta_W[nn.num_hidden_layer - j],np.sqrt(vt_w[j] + epsilon)) - lr*weight_decay*nn.W[j]\n",
    "          nn.b[j] = nn.b[j] - np.divide(lr * delta_b[nn.num_hidden_layer - j],np.sqrt(vt_b[j] + epsilon))\n",
    "\n",
    "      Y_hat = nn.feedforward(X)\n",
    "      loss_value = nn.loss(Y_hat,Y,weight_decay,nn.W)\n",
    "      print(f\"epoch: {epoch} => loss = {loss_value}\")\n",
    "      y_val_predict = nn.feedforward(X_val)\n",
    "      y_train_predict = nn.feedforward(X)\n",
    "\n",
    "      validation_loss = nn.loss(y_val_predict,Y_val,weight_decay,nn.W)\n",
    "      training_loss = nn.loss(y_train_predict,Y,weight_decay,nn.W)\n",
    "\n",
    "      validation_accuracy = nn.calculateAccuracy(X_val, Y_val)\n",
    "      training_accuracy = nn.calculateAccuracy(X, Y)\n",
    "\n",
    "      \n",
    "      val_loss_list.append(validation_loss)\n",
    "      val_accuracy_list.append(validation_accuracy)\n",
    "      train_loss_list.append(training_loss)\n",
    "      train_accuracy_list.append(training_accuracy)\n",
    "    \n",
    "    return val_loss_list,val_accuracy_list,train_loss_list,train_accuracy_list\n",
    "    \n",
    "  def adam(self, nn, X, Y, X_val, Y_val, lr, epochs, batch_size,indexes_for_batch,parameters = [0.9,0.99,0.1], weight_decay = 0):\n",
    "    num_data = X.shape[1]\n",
    "    vt_w,vt_b = nn.initializeWeights(\"zero\")\n",
    "    mt_w,mt_b = nn.initializeWeights(\"zero\")\n",
    "    beta1 = parameters[0]\n",
    "    beta2 = parameters[1]\n",
    "    epsilon = parameters[2]\n",
    "\n",
    "    t=0\n",
    "\n",
    "    val_loss_list = []\n",
    "    train_loss_list = []\n",
    "    val_accuracy_list = []\n",
    "    train_accuracy_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      for batch in range(0,num_data,batch_size):\n",
    "        t+=1\n",
    "        X_batch = X[:,indexes_for_batch[batch:batch + batch_size]]\n",
    "        Y_batch = Y[indexes_for_batch[batch:batch + batch_size]]\n",
    "\n",
    "        # self.W,self.b = self.initializeWeights()\n",
    "        a_values,h_values = nn.forwardpropogation(X_batch)\n",
    "        delta_W, delta_b = nn.backpropogation(X_batch,Y_batch,a_values, h_values)\n",
    "        # print(np.sum(delta_W[0], axis = 0))\n",
    "        for j in range(nn.num_hidden_layer + 1):\n",
    "          mt_w[j] = beta1 * mt_w[j] + (1 - beta1) * delta_W[nn.num_hidden_layer - j]\n",
    "          mt_b[j] = beta1 * mt_b[j] + (1 - beta1) * delta_b[nn.num_hidden_layer - j]\n",
    "\n",
    "          mt_w_dash = mt_w[j] / (1 - beta1 ** t)\n",
    "          mt_b_dash = mt_b[j] / (1 - beta1 ** t)\n",
    "\n",
    "\n",
    "          vt_w[j] = beta2*vt_w[j] + (1 - beta2) * np.multiply(delta_W[nn.num_hidden_layer - j],delta_W[nn.num_hidden_layer - j]) \n",
    "          vt_b[j] = beta2*vt_b[j] + (1 - beta2) * np.multiply(delta_b[nn.num_hidden_layer - j],delta_b[nn.num_hidden_layer - j])\n",
    "\n",
    "          vt_w_dash = vt_w[j] / (1 - beta2 ** t)\n",
    "          vt_b_dash = vt_b[j] / (1 - beta2 ** t)           \n",
    "\n",
    "          nn.W[j] = nn.W[j] - np.divide(lr * mt_w_dash,np.sqrt(vt_w_dash + epsilon)) - lr*weight_decay*nn.W[j]\n",
    "          nn.b[j] = nn.b[j] - np.divide(lr * mt_b_dash,np.sqrt(vt_b_dash + epsilon))\n",
    "\n",
    "      Y_hat = nn.feedforward(X)\n",
    "      loss_value = nn.loss(Y_hat,Y,weight_decay,nn.W)\n",
    "      print(f\"epoch: {epoch} => loss = {loss_value}\")\n",
    "      y_val_predict = nn.feedforward(X_val)\n",
    "      y_train_predict = nn.feedforward(X)\n",
    "\n",
    "      validation_loss = nn.loss(y_val_predict,Y_val,weight_decay,nn.W)\n",
    "      training_loss = nn.loss(y_train_predict,Y,weight_decay,nn.W)\n",
    "\n",
    "      validation_accuracy = nn.calculateAccuracy(X_val, Y_val)\n",
    "      training_accuracy = nn.calculateAccuracy(X, Y)\n",
    "\n",
    "      \n",
    "      val_loss_list.append(validation_loss)\n",
    "      val_accuracy_list.append(validation_accuracy)\n",
    "      train_loss_list.append(training_loss)\n",
    "      train_accuracy_list.append(training_accuracy)\n",
    "    \n",
    "    return val_loss_list,val_accuracy_list,train_loss_list,train_accuracy_list\n",
    "    \n",
    "  def nadam(self, nn, X, Y,X_val, Y_val, lr, epochs, batch_size,indexes_for_batch,parameters = [0.9, 0.999, 0.1], weight_decay = 0):\n",
    "    num_data = X.shape[1]\n",
    "    vt_w,vt_b = nn.initializeWeights(\"zero\")\n",
    "    mt_w,mt_b = nn.initializeWeights(\"zero\")\n",
    "    beta1 = parameters[0]\n",
    "    beta2 = parameters[1]\n",
    "    epsilon = parameters[2]\n",
    "\n",
    "    t=0\n",
    "\n",
    "    val_loss_list = []\n",
    "    train_loss_list = []\n",
    "    val_accuracy_list = []\n",
    "    train_accuracy_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      for batch in range(0,num_data,batch_size):\n",
    "        t+=1\n",
    "        X_batch = X[:,indexes_for_batch[batch:batch + batch_size]]\n",
    "        Y_batch = Y[indexes_for_batch[batch:batch + batch_size]]\n",
    "\n",
    "        # self.W,self.b = self.initializeWeights()\n",
    "        a_values,h_values = nn.forwardpropogation(X_batch)\n",
    "        delta_W, delta_b = nn.backpropogation(X_batch,Y_batch,a_values, h_values)\n",
    "        # print(np.sum(delta_W[0], axis = 0))\n",
    "        for j in range(nn.num_hidden_layer + 1):\n",
    "          mt_w[j] = beta1 * mt_w[j] + (1 - beta1) * delta_W[nn.num_hidden_layer - j]\n",
    "          mt_b[j] = beta1 * mt_b[j] + (1 - beta1) * delta_b[nn.num_hidden_layer - j]\n",
    "\n",
    "          mt_w_dash = mt_w[j] / (1 - beta1 ** t)\n",
    "          mt_b_dash = mt_b[j] / (1 - beta1 ** t)\n",
    "\n",
    "\n",
    "          vt_w[j] = beta2*vt_w[j] + (1 - beta2) * np.multiply(delta_W[nn.num_hidden_layer - j],delta_W[nn.num_hidden_layer - j]) \n",
    "          vt_b[j] = beta2*vt_b[j] + (1 - beta2) * np.multiply(delta_b[nn.num_hidden_layer - j],delta_b[nn.num_hidden_layer - j])\n",
    "\n",
    "          vt_w_dash = vt_w[j] / (1 - beta2 ** t)\n",
    "          vt_b_dash = vt_b[j] / (1 - beta2 ** t)           \n",
    "\n",
    "          w_update_numerator = lr * (beta1 * mt_w_dash + ((1 - beta1)* delta_W[nn.num_hidden_layer - j]/(1 - beta1 ** t)))\n",
    "          b_update_numerator = lr * (beta1 * mt_b_dash + ((1 - beta1)* delta_b[nn.num_hidden_layer - j]/(1 - beta1 ** t)))\n",
    "\n",
    "          nn.W[j] = nn.W[j] - np.divide(w_update_numerator,np.sqrt(vt_w_dash + epsilon)) - lr*weight_decay*nn.W[j]\n",
    "          nn.b[j] = nn.b[j] - np.divide(b_update_numerator,np.sqrt(vt_b_dash + epsilon))\n",
    "\n",
    "      Y_hat = nn.feedforward(X)\n",
    "      loss_value = nn.loss(Y_hat,Y,weight_decay,nn.W)\n",
    "      print(f\"epoch: {epoch} => loss = {loss_value}\")\n",
    "      y_val_predict = nn.feedforward(X_val)\n",
    "      y_train_predict = nn.feedforward(X)\n",
    "\n",
    "      validation_loss = nn.loss(y_val_predict,Y_val,weight_decay,nn.W)\n",
    "      training_loss = nn.loss(y_train_predict,Y,weight_decay,nn.W)\n",
    "\n",
    "      validation_accuracy = nn.calculateAccuracy(X_val, Y_val)\n",
    "      training_accuracy = nn.calculateAccuracy(X, Y)\n",
    "\n",
    "      \n",
    "      val_loss_list.append(validation_loss)\n",
    "      val_accuracy_list.append(validation_accuracy)\n",
    "      train_loss_list.append(training_loss)\n",
    "      train_accuracy_list.append(training_accuracy)\n",
    "    \n",
    "    return val_loss_list,val_accuracy_list,train_loss_list,train_accuracy_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5lWfym6w4BKL"
   },
   "outputs": [],
   "source": [
    "# Base class for all neural networks\n",
    "\n",
    "class NeuralNetwork():\n",
    "  def __init__(self):\n",
    "    pass\n",
    "  def getParameters(self):\n",
    "    pass\n",
    "  def feedforward():\n",
    "    pass\n",
    "  def backpropogation():\n",
    "    pass\n",
    "  def test(self):\n",
    "    pass\n",
    "  def train(self):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EPQ7zGjg6gEk"
   },
   "outputs": [],
   "source": [
    "# Neural Network for this particular neural network\n",
    "\n",
    "class NN(NeuralNetwork):\n",
    "\n",
    "  '''\n",
    "  It contains the neural network desired for this application.\n",
    "  Hidden layers, its sizes etc are all dynamic and can be set.\n",
    "  \n",
    "  '''\n",
    "  def __init__(self, num_samples = 60000, input_size = 784, output_size = 10, num_hidden_layer = 3, hidden_layer_size=np.array([64,64,64]), data_name = \"Fashion_mnsit\", hidden_layer_activation=\"relu\", output_layer_activation=\"softmax\", weight_name=\"xavier\",loss_name=\"cross_entropy\"):\n",
    "    self.num_samples = num_samples\n",
    "    self.input_size = input_size\n",
    "    self.output_size = output_size\n",
    "    self.num_hidden_layer = num_hidden_layer\n",
    "    self.hidden_layer_size = hidden_layer_size\n",
    "    self.W, self.b = self.initializeWeights(weight_name)\n",
    "    self.hidden_layer_activation = hidden_layer_activation\n",
    "    self.output_layer_activation = output_layer_activation\n",
    "    self.loss_name = loss_name\n",
    "    self.activation_function = Activations()\n",
    "    self.activate_hidden = self.activation_function.activate(hidden_layer_activation)\n",
    "    self.activate_hidden_derivative = self.activation_function.derivate(hidden_layer_activation)\n",
    "    self.activate_output = self.activation_function.activate(output_layer_activation)\n",
    "    self.lossFunction = Loss(loss_name)\n",
    "    self.loss = self.lossFunction.findLoss()\n",
    "    self.lossDerivative = self.lossFunction.findDerivative()\n",
    "    self.parameters = {\n",
    "        \"data_name\":data_name,\n",
    "        \"num_samples\":num_samples,\n",
    "        \"input_size\":input_size,\n",
    "        \"output_size\":output_size,\n",
    "        \"num_hidden_layer\":num_hidden_layer,\n",
    "        \"hidden_layer_size\":hidden_layer_size,\n",
    "        \"hidden_layer_activation\":hidden_layer_activation,\n",
    "        \"output_layer_activation\":output_layer_activation,\n",
    "        \"weight_init\":weight_name,\n",
    "        \"loss_name\":loss_name\n",
    "    }\n",
    "\n",
    "  def getParameters(self):\n",
    "    return self.parameters\n",
    "\n",
    "  def initializeWeights(self, weight_name):\n",
    "    W = []\n",
    "    b= []\n",
    "    input_size = self.input_size\n",
    "    weight_init = WeightInit(weight_name).initializeWeight()\n",
    "    for i in range(self.num_hidden_layer):\n",
    "      output_size = self.hidden_layer_size[i]\n",
    "      W.append(weight_init((input_size, output_size ),0))\n",
    "      b.append(weight_init((output_size, 1 ),1))\n",
    "      input_size = output_size\n",
    "    \n",
    "    output_size = self.output_size\n",
    "\n",
    "    W.append(weight_init((input_size, output_size),0))\n",
    "    b.append(weight_init((output_size, 1),1))\n",
    "\n",
    "    return W, b\n",
    "\n",
    "  def calculateAccuracy(self, X, Y):\n",
    "    Y_hat = self.feedforward(X)\n",
    "    size = Y_hat.shape[1]\n",
    "    score=0\n",
    "    for i in range(size):\n",
    "      if(np.argmax(Y_hat[:,i]) ==  Y[i]):\n",
    "          score+=1\n",
    "\n",
    "    return score/size * 100\n",
    "\n",
    "  def feedforward(self, X):\n",
    "    a = self.W[0].T @ X + self.b[0]\n",
    "    hidden_layer_input = self.activate_hidden(a)\n",
    "\n",
    "    for i in range(1,self.num_hidden_layer):\n",
    "      a=self.W[i].T @ hidden_layer_input + self.b[i]\n",
    "      hidden_layer_output=self.activate_hidden(a)\n",
    "      hidden_layer_input = hidden_layer_output\n",
    "\n",
    "    a=self.W[self.num_hidden_layer].T @ hidden_layer_input + self.b[self.num_hidden_layer]\n",
    "    output = self.activate_output(a)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "  def forwardpropogation(self, X):\n",
    "    a_values=[]\n",
    "    h_values=[]\n",
    "\n",
    "    a = self.W[0].T @ X + self.b[0]\n",
    "    hidden_layer_input = self.activate_hidden(a)\n",
    "    \n",
    "    a_values.append(a)\n",
    "    h_values.append(hidden_layer_input)\n",
    "\n",
    "    for i in range(1,self.num_hidden_layer):\n",
    "      a=self.W[i].T @ hidden_layer_input + self.b[i]\n",
    "      hidden_layer_output=self.activate_hidden(a)\n",
    "      hidden_layer_input = hidden_layer_output\n",
    "      a_values.append(a)\n",
    "      h_values.append(hidden_layer_input)\n",
    "\n",
    "    a=self.W[self.num_hidden_layer].T @ hidden_layer_input + self.b[self.num_hidden_layer]\n",
    "    output = self.activate_output(a)\n",
    "    a_values.append(a)\n",
    "    h_values.append(output)\n",
    "\n",
    "    return a_values,h_values\n",
    "\n",
    "  def backpropogation(self, X, Y, a_values, h_values):\n",
    "    size = len(h_values)\n",
    "    data_size = Y.shape[0]\n",
    "    delta_ak = self.lossDerivative(h_values[size - 1],Y)\n",
    "    delta_W=[]\n",
    "    delta_b=[]\n",
    "\n",
    "    for k in range(size - 1,0,-1):\n",
    "      delta_wk = h_values[k-1] @ delta_ak.T\n",
    "      delta_bk = np.sum(delta_ak,axis=1)\n",
    "      delta_W.append(delta_wk/data_size)\n",
    "      delta_b.append(delta_bk.reshape(delta_bk.shape[0],1)/data_size)\n",
    "\n",
    "      delta_hk = self.W[k] @ delta_ak\n",
    "      # print(delta_hk.shape)\n",
    "      # print(self.activation_function.sigmoidDerivative(a_values[k-1]).shape)\n",
    "      delta_ak = np.multiply(self.activate_hidden_derivative(a_values[k-1]),delta_hk)\n",
    "\n",
    "    delta_wk = X @ delta_ak.T\n",
    "    delta_bk = np.sum(delta_ak,axis=1)\n",
    "    delta_W.append(delta_wk/data_size)\n",
    "    delta_b.append(delta_bk.reshape(delta_bk.shape[0],1)/data_size)\n",
    "\n",
    "    return delta_W,delta_b\n",
    "  \n",
    "  def training(self, X, Y, X_val, Y_val ,epochs = 10 , weight_decay = 0 ,optimizer_name=\"gd\", lr=0.01, batch_size=32,parameters=[]):\n",
    "    optimize = Optimizer(optimizer_name).optimize()\n",
    "    \n",
    "    num_data = X.shape[1]\n",
    "    np.random.seed(1)\n",
    "\n",
    "    # Random shuffling of data\n",
    "    indexes_for_batch = np.arange(num_data)\n",
    "    np.random.shuffle(indexes_for_batch)\n",
    "\n",
    "    return optimize(self, X, Y, X_val, Y_val , lr, epochs, batch_size, indexes_for_batch, weight_decay=weight_decay)\n",
    "#     print(f'train accuracy: {self.calculateAccuracy(X,Y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wandb running part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wsFVNClaZ_Vs"
   },
   "outputs": [],
   "source": [
    "# # Split data to train and validation (10% of data)\n",
    "num_train_samples = 60000\n",
    "num_validate_samples = num_train_samples//10\n",
    "num_train_samples -= num_validate_samples\n",
    "\n",
    "X_valid = X_train[:num_validate_samples,:].reshape(num_validate_samples,num_size).T /255.0\n",
    "Y_valid = Y_train[:num_validate_samples]\n",
    "\n",
    "X = X_train[num_validate_samples:,:].reshape(num_train_samples,num_size).T / 255.0\n",
    "Y = Y_train[num_validate_samples:]\n",
    "\n",
    "def train():\n",
    "\n",
    "  wandb.init()\n",
    "\n",
    "  num_hidden_layer = wandb.config.num_hidden_layer\n",
    "  hidden_layer_size = np.full(num_hidden_layer,wandb.config.hidden_size)\n",
    "  hidden_layer_activation = wandb.config.activation\n",
    "  weight_name = wandb.config.weight_init\n",
    "  epochs = wandb.config.epochs\n",
    "  weight_decay = wandb.config.weight_decay\n",
    "  optimizer_name = wandb.config.optimizer\n",
    "  lr = wandb.config.lr\n",
    "  batch_size = wandb.config.batch_size\n",
    "\n",
    "  wandb.run.name = f'hln_{num_hidden_layer}_hls_{wandb.config.hidden_size}_hla_{hidden_layer_activation}_winit_{weight_name}_ep_{epochs}_op_{optimizer_name}_lr_{lr}_bs_{batch_size}_wd_{weight_decay}'\n",
    "\n",
    "#   loss = Loss('cross_entropy').findLoss()\n",
    "  nn = NN(num_samples = num_train_samples, num_hidden_layer = num_hidden_layer, hidden_layer_size = hidden_layer_size, hidden_layer_activation = hidden_layer_activation, weight_name = weight_name,loss_name = 'cross_entropy')\n",
    "  val_loss_list,val_accuracy_list,train_loss_list,train_accuracy_list = nn.training(X, Y, X_valid, Y_valid, epochs = epochs, weight_decay = weight_decay, optimizer_name = optimizer_name,lr = lr, batch_size = batch_size)\n",
    "\n",
    "  print(val_loss_list,val_accuracy_list,train_loss_list,train_accuracy_list)\n",
    "  for i in range(len(val_loss_list)):\n",
    "    wandb.log({'validation_loss': val_loss_list[i],\n",
    "              'training_loss': train_loss_list[i],\n",
    "              'validation_accuracy': val_accuracy_list[i],\n",
    "              'training_accuracy': train_accuracy_list[i]\n",
    "              })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run below part for sweeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550,
     "referenced_widgets": [
      "abc15c3f641546ecbc90e8bdd6a941ce",
      "910c5f78e0254062a3e7f269e454b8e2",
      "2e74356e6ea94b51bf8c039da82c1994",
      "d95345eee8bd4cfe81d10819f39f63a0",
      "1b794ec70f6645968425eb6d27db449d",
      "368929f2d8d84b789ca7ef2e584c638f",
      "7fef93c2a6184e93aee29efe40d9ebd6",
      "1afc886b32764c6d9d9d17eab6391c4b"
     ]
    },
    "id": "BaV_JvwppDeV",
    "outputId": "79f1a3ab-a8dd-4701-ca8f-38f59cf417e3"
   },
   "outputs": [],
   "source": [
    "# Wand sweep part change different config values and see different runs\n",
    "sweep_configuration = {\n",
    "    'method': 'random',\n",
    "    'name': 'dl-project-final-production',\n",
    "    'metric': {\n",
    "        'goal': 'minimize', \n",
    "        'name': 'validation_loss'\n",
    "        },\n",
    "    'parameters': {\n",
    "        'batch_size': {'values': [16, 32, 64]},\n",
    "        'epochs': {'values': [5, 10]},\n",
    "        'num_hidden_layer':{'values' : [3, 4, 5]},\n",
    "        'hidden_size': {'values' : [32, 64, 128]},\n",
    "        'weight_decay': {'values' : [0, 0.0005, 0.5]},\n",
    "        'lr': {'values' : [1e-3, 1e-4]},\n",
    "        'optimizer':{'values' : ['sgd', 'momentum', 'nag', 'rmsprop', 'adam', 'nadam']},\n",
    "        'weight_init':{'values' : ['random','xavier']},\n",
    "        'activation' : {'values' : ['sigmoid','tanh','relu']},\n",
    "     }\n",
    "}\n",
    "\n",
    "wandb.login(key = 'c425b887e2c725018a7f3a772582610fa54ef52c')\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project='dl-project-final-production')\n",
    "wandb.agent(sweep_id, function=train, count=10000)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For running without the sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "class_count = len(class_names)\n",
    "\n",
    "\n",
    "def convertToConfusionMatrix(Y_hat_label, Y_labels):\n",
    "    confusion_matrix = np.zeros((class_count,class_count),dtype=int)\n",
    "    for i in range(len(Y_hat_label)):\n",
    "        confusion_matrix[Y_hat_label[i]][class_count - 1 - Y_labels[i] ]+=1\n",
    "    return confusion_matrix\n",
    "    \n",
    "def confusionMatrixPlot(Y_hat_label, Y_labels):\n",
    "    confusion_matrix = convertToConfusionMatrix(Y_hat_label, Y_labels)\n",
    "    confusion_matrix_normalized = confusion_matrix / confusion_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "    cmap = plt.cm.get_cmap('Reds')\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(confusion_matrix_normalized.T, cmap=cmap, vmin=0, vmax=1)\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.xticks(ticks=[i for i in range(class_count)], labels=class_names)\n",
    "    plt.yticks(ticks=[i for i in range(class_count-1,-1,-1)], labels=class_names)\n",
    "    \n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "\n",
    "    for i in range(class_count):\n",
    "        for j in range(class_count):\n",
    "            plt.text(i, j, f'{confusion_matrix[i, j]}', ha='center', va='center', color='black')\n",
    "\n",
    "    plt.title('Confusion Matrix')\n",
    "    \n",
    "    canvas = plt.gca().figure.canvas\n",
    "    canvas.draw()\n",
    "    data = np.frombuffer(canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    image = data.reshape(canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.show()\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run below for trying different configurations without sweep and testing and plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GMaTOGnTMt7U",
    "outputId": "d6153e4e-df6d-4e57-a2a2-517f71702883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 => loss = 0.42647247745134936\n",
      "epoch: 1 => loss = 0.3793968867614388\n",
      "epoch: 2 => loss = 0.3534259672291089\n",
      "epoch: 3 => loss = 0.3337748645737256\n",
      "epoch: 4 => loss = 0.3174427400380416\n",
      "epoch: 5 => loss = 0.30247535832285183\n",
      "epoch: 6 => loss = 0.2888302560767463\n",
      "epoch: 7 => loss = 0.2766053498755096\n",
      "epoch: 8 => loss = 0.2655880838351924\n",
      "epoch: 9 => loss = 0.2557177053079512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m058\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/tharikh/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a390f3763341ff8a91f38f82a0cb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01667073356657056, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tharikh/dl-ass-1/wandb/run-20230319_214232-772segsy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs22m058/dl-project-final/runs/772segsy' target=\"_blank\">astral-bush-692</a></strong> to <a href='https://wandb.ai/cs22m058/dl-project-final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs22m058/dl-project-final' target=\"_blank\">https://wandb.ai/cs22m058/dl-project-final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs22m058/dl-project-final/runs/772segsy' target=\"_blank\">https://wandb.ai/cs22m058/dl-project-final/runs/772segsy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">astral-bush-692</strong> at: <a href='https://wandb.ai/cs22m058/dl-project-final/runs/772segsy' target=\"_blank\">https://wandb.ai/cs22m058/dl-project-final/runs/772segsy</a><br/>Synced 5 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230319_214232-772segsy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss : 0.2557177053079512 \n",
      "training accuracy : 90.52037037037037\n",
      "tesing loss : 0.3558919259989633 \n",
      "testing accuracy : 87.24 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
    "num_train_samples = X_train.shape[0]\n",
    "num_test_samples = X_test.shape[0]\n",
    "num_validate_samples = num_train_samples//10\n",
    "num_train_samples -= num_validate_samples\n",
    "\n",
    "X_valid = X_train[:num_validate_samples,:].reshape(num_validate_samples,input_size).T /255.0\n",
    "Y_valid = Y_train[:num_validate_samples]\n",
    "\n",
    "X = X_train[num_validate_samples:,:].reshape(num_train_samples,input_size).T / 255.0\n",
    "Y = Y_train[num_validate_samples:]\n",
    "\n",
    "X_test = X_test.reshape(num_test_samples,input_size).T / 255.0\n",
    "Y_test = Y_test\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "activation = 'tanh'\n",
    "batch_size=16\n",
    "epochs=10\n",
    "hidden_size= 128\n",
    "lr= 0.001\n",
    "num_hidden_layer= 5\n",
    "optimizer='momentum'\n",
    "weight_decay=0\n",
    "weight_init='xavier'\n",
    "loss_name = 'cross_entropy'\n",
    "\n",
    "# loss = Loss('cross_entropy').findLoss()\n",
    "nn = NN(num_samples = num_train_samples, num_hidden_layer = num_hidden_layer, hidden_layer_size = np.full(num_hidden_layer,hidden_size), hidden_layer_activation = activation, weight_name = weight_init,loss_name=loss_name)\n",
    "val_loss_list,val_accuracy_list,train_loss_list,train_accuracy_list = nn.training(X, Y,X_valid,Y_valid, epochs = epochs, weight_decay = weight_decay, optimizer_name = optimizer,lr = lr, batch_size = batch_size)\n",
    "\n",
    "test_predict = nn.feedforward(X_test)\n",
    "test_predict_label_format = np.argmax(test_predict,axis=0)\n",
    "test_loss = nn.loss(test_predict,Y_test)\n",
    "test_accuracy = nn.calculateAccuracy(X_test, Y_test)\n",
    "\n",
    "list_length = len(val_loss_list)\n",
    "\n",
    "wandb.login(key = 'c425b887e2c725018a7f3a772582610fa54ef52c')\n",
    "wandb.init(project=\"dl-project-final\")\n",
    "wandb.run.name = f'confusion matrix for training using matplotlib and wandb'\n",
    "# for i in range(list_length):\n",
    "#   wandb.log({'validation_loss': val_loss_list[i],\n",
    "#             'training_loss': train_loss_list[i],\n",
    "#             'validation_accuracy': val_accuracy_list[i],\n",
    "#             'training_accuracy': train_accuracy_list[i]\n",
    "#             })\n",
    "\n",
    "# wandb.log({'testing_loss': test_loss,\n",
    "#             'testing_accuracy': test_accuracy\n",
    "#             })\n",
    "\n",
    "\n",
    "wandb.log({\"conf_mat_wandb\" : wandb.plot.confusion_matrix(probs=None,\n",
    "                        y_true=Y_test, preds=test_predict_label_format,class_names=class_names)})\n",
    "# Visualize single plot\n",
    "image = confusionMatrixPlot(test_predict_label_format, Y_test)\n",
    "wandb.log({\"conf_mat_matplotlib\" : [wandb.Image(image,caption=\"Confusion Matrix\")]})\n",
    "\n",
    "wandb.finish()\n",
    "print(f'training loss : {train_loss_list[list_length-1]} \\ntraining accuracy : {train_accuracy_list[list_length-1]}\\ntesing loss : {test_loss} \\ntesting accuracy : {test_accuracy} \\n ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMKTYedF4uTe89A1e55M08b",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1afc886b32764c6d9d9d17eab6391c4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b794ec70f6645968425eb6d27db449d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e74356e6ea94b51bf8c039da82c1994": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7fef93c2a6184e93aee29efe40d9ebd6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1afc886b32764c6d9d9d17eab6391c4b",
      "value": 0.0785171540409855
     }
    },
    "368929f2d8d84b789ca7ef2e584c638f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fef93c2a6184e93aee29efe40d9ebd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "910c5f78e0254062a3e7f269e454b8e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b794ec70f6645968425eb6d27db449d",
      "placeholder": "​",
      "style": "IPY_MODEL_368929f2d8d84b789ca7ef2e584c638f",
      "value": "0.001 MB of 0.008 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "abc15c3f641546ecbc90e8bdd6a941ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_910c5f78e0254062a3e7f269e454b8e2",
       "IPY_MODEL_2e74356e6ea94b51bf8c039da82c1994"
      ],
      "layout": "IPY_MODEL_d95345eee8bd4cfe81d10819f39f63a0"
     }
    },
    "d95345eee8bd4cfe81d10819f39f63a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
